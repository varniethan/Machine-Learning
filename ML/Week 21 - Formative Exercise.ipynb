{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f5bb55",
   "metadata": {},
   "source": [
    "# Week 21 - Formative Exercise\n",
    "\n",
    "This week you're given a scenario below, you must select appropriate techniques to consider, train at least two models based on the scenario and then finally evaluate your models using reasonable metrics. \n",
    "\n",
    "## Scenario\n",
    "You are working as a data scientist at the Met Office.\n",
    "\n",
    "Wales is particularly succeptible to climate change which is increasing the frequency of both flooding and drought events. Luckily temperature and rainfall records are well kept for four stations in Wales.\n",
    "\n",
    "To help identify the future state of the climate in Wales you have been asked to conduct one of the two tasks below, choose one which interests you the most.\n",
    "\n",
    "### Task 1: Rainfall Prediction\n",
    "The first option is to produce a model capable of predicting the rainfall in June of 2100.\n",
    "\n",
    "### Task 2: Temperature Prediction\n",
    "The second option is to produce a model capable of predicting the temperature in September of 2150.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "You have been provided a weather dataset for four weather stations across Wales, these are:\n",
    "+ 0: Valley\n",
    "+ 1: Cardiff\n",
    "+ 2: Ross-on-Wye\n",
    "+ 3: Aberporth\n",
    "\n",
    "<div>\n",
    "<img src=\"wales.png\" width=\"250\"/>\n",
    "</div>\n",
    "\n",
    "The dataset is provided in a Numpy array format which can be loaded as follows:\n",
    "\n",
    "`dataset = np.loadtxt(\"weather_data.csv\", delimiter=\",\")`\n",
    "\n",
    "Once you have loaded the dataset it will look like a numpy array consisting of 5 columns which are as follows:\n",
    "1. Weather Station (a numerical indicator as defined above)\n",
    "2. Year of the reading\n",
    "3. Month of the reading\n",
    "4. Temperature (Degrees Celsius)\n",
    "5. Rainfall (mm)\n",
    "\n",
    "You do not have to use all the data; however, you should consider carefully which data you need to successfully train and test a model to answer the questions.\n",
    "\n",
    "## Recommended Steps\n",
    "\n",
    "To help you answer the questions here are a list of steps I recommend you take to tackle each question individually:\n",
    "1. Load the data from the `weather_data.csv` file.\n",
    "2. Extract only the inputs and outputs you need.\n",
    "3. Split the data into training and testing.\n",
    "4. Select a suitable modelling approach.\n",
    "5. Implement and fit the model.\n",
    "6. Evaluate the model's performance.\n",
    "7. (Optional) Try a second modelling approach to compare performance!\n",
    "\n",
    "## Tips and Tricks\n",
    "\n",
    "Now you've got a handle on the metrics necessary for evaluating tasks I recommend you make use of the sklearn metrics library so you don't need to implement them yourself! Take a look through the [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) documentation, you'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1eae9",
   "metadata": {},
   "source": [
    "Task 1: Rainfall Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b71d8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6c2430a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 1.930e+03 1.200e+01 8.600e+00 1.303e+02]\n",
      " [0.000e+00 1.931e+03 1.000e+00 8.000e+00 6.620e+01]\n",
      " [0.000e+00 1.931e+03 2.000e+00 7.600e+00 6.060e+01]\n",
      " ...\n",
      " [3.000e+00 2.022e+03 1.000e+01 1.560e+01 1.074e+02]\n",
      " [3.000e+00 2.022e+03 1.100e+01 1.190e+01 1.182e+02]\n",
      " [3.000e+00 2.022e+03 1.200e+01 7.600e+00 8.060e+01]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('weather_data.csv', delimiter=',')\n",
    "# Weather station, Year, Month, Temperature, Rainfall\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ae4fc674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3719, 5)\n",
      "860.019539116975\n",
      "24.790568455301287\n",
      "29.326089734517538\n"
     ]
    }
   ],
   "source": [
    "#From the dataset, get rid of the row that doesn't have valye 6 in the 3rd collumn\n",
    "june_dataset = dataset[dataset[:, 2] == 5]\n",
    "\n",
    "print(dataset.shape)\n",
    "# Split the dataset into train and test\n",
    "train_x, test_x, train_y, test_y = train_test_split(june_dataset[:,:4], june_dataset[:,-1], test_size=0.3)\n",
    "\n",
    "# Create linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "linear_model.fit(train_x, train_y)\n",
    "\n",
    "# Test the model\n",
    "y_pred = linear_model.predict(test_x)\n",
    "\n",
    "# Evaluate the model\n",
    "print(mean_squared_error(test_y, y_pred))\n",
    "print(mean_absolute_error(test_y, y_pred))\n",
    "print(root_mean_squared_error(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b0ea54ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968.5627182795698\n",
      "24.13677419354839\n",
      "31.121740283595482\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test\n",
    "train_x, test_x, train_y, test_y = train_test_split(june_dataset[:,:4], june_dataset[:,-1], test_size=0.3)\n",
    "\n",
    "# Create linear regression model\n",
    "linear_model = KNeighborsRegressor(n_neighbors = 5)\n",
    "\n",
    "# Train the model\n",
    "linear_model.fit(train_x, train_y)\n",
    "\n",
    "# Test the model\n",
    "y_pred = linear_model.predict(test_x)\n",
    "\n",
    "# Evaluate the model\n",
    "print(mean_squared_error(test_y, y_pred))\n",
    "print(mean_absolute_error(test_y, y_pred))\n",
    "print(root_mean_squared_error(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9437f8f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [310, 3719]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m test \u001b[38;5;241m=\u001b[39m dataset[:, \u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# Target: Temperature\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Split the dataset into train and test\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_x, test_x, train_y, test_y \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create random forest model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2662\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:476\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 476\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    433\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [310, 3719]"
     ]
    }
   ],
   "source": [
    "september_dataset = dataset[dataset[:, 2] == 8]\n",
    "\n",
    "# Assuming dataset is your numpy array\n",
    "train = np.concatenate((september_dataset[:, 0:3], september_dataset[:, 4].reshape(-1, 1)), axis=1)  # Features: Weather station, Year, Month, Rainfall\n",
    "test = dataset[:, 3]  # Target: Temperature\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train_x, test_x, train_y, test_y = train_test_split(train, test, test_size=0.3)\n",
    "\n",
    "# Create random forest model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "linear_model.fit(train_x, train_y)\n",
    "\n",
    "# Test the model\n",
    "y_pred = linear_model.predict(test_x)\n",
    "\n",
    "# Evaluate the model\n",
    "print(mean_squared_error(test_y, y_pred))\n",
    "print(mean_absolute_error(test_y, y_pred))\n",
    "print(root_mean_squared_error(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755d1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a9c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
