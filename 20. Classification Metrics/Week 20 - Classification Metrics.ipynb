{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db56340",
   "metadata": {},
   "source": [
    "# Week 20 - Classification Metrics\n",
    "\n",
    "This week's exercises will focus on classification and the use of different metrics in evaluating classifier performance.\n",
    "\n",
    "The learning objectives of this lab are as follows:\n",
    "1. Implement two classification models using modern Python library.\n",
    "2. Implement methods to calculate precision and recall for a given set of results.\n",
    "3. Compare and contrast two classification models using precision and recall.\n",
    "\n",
    "To begin, let's set up some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, make_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c6eea",
   "metadata": {},
   "source": [
    "## 1. Creating Classifiers\n",
    "\n",
    "To begin, we will use the same dataset as last week, the Iris flower dataset. This dataset not only contains four features of various iris flowers but also contains which type of Iris flower they refer to.\n",
    "\n",
    "The code below loads the features of the flowers into training and testing datasets.\n",
    "\n",
    "1. `train_x` contains the features for flowers in the training dataset.\n",
    "2. `test_x` contains the features for flowers in the testing dataset.\n",
    "3. `train_y` contains the classifications for flowers in the training dataset.\n",
    "4. `test_y` contains the classifications for flowers in the testing dataset.\n",
    "\n",
    "These have been generated using the `train_test_split` method in sklearn which randomly splits the data into training and testing based on the percentage of test items indicated in the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "iris_x = iris_data['data']\n",
    "iris_y = iris_data['target']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris_x, iris_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351ba6a",
   "metadata": {},
   "source": [
    "Next, for context let's take a look a the number of each classification in the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are the following classes in the training dataset:\")\n",
    "for idx, cls in enumerate(iris_data['target_names']):\n",
    "    cls_count = train_y[train_y == idx].shape[0]\n",
    "    print(f\"\\t>{cls}: {cls_count}\")\n",
    "print(\"There are the following classes in the testing dataset:\")\n",
    "for idx, cls in enumerate(iris_data['target_names']):\n",
    "    cls_count = test_y[test_y == idx].shape[0]\n",
    "    print(f\"\\t> {cls}: {cls_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ce376",
   "metadata": {},
   "source": [
    "### 1.1 TASK: Logistic Regression\n",
    "\n",
    "Use the `LogisticRegression` class to train a Logistic Regression classifier which can classify between the different types of flowers given in the Iris dataset.\n",
    "\n",
    "To do this you will need to use the `train_x` and `train_y` datasets with the `.fit()` method, you may also want to increase the number of iterations used through the `max_iter` parameter.\n",
    "\n",
    "For full details of the Logistic Regression method in Sklearn please see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e9aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "945768c7",
   "metadata": {},
   "source": [
    "### 1.2 TASK: Decision Tree\n",
    "\n",
    "Use the `DecisionTreeClassifier` class to train a Logistic Regression classifier which can classify between the different types of flowers given in the Iris dataset.\n",
    "\n",
    "To do this you will need to use the `train_x` and `train_y` datasets with the `.fit()` method, you may also want to increase the number of iterations used through the `max_iter` parameter.\n",
    "\n",
    "For full details of the Decision Tree Classifier method in Sklearn please see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abfd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba165598",
   "metadata": {},
   "source": [
    "For context, the decision tree algorithm here uses CART by default which uses something called the 'Gini impurity' instead of entropy. To force the algorithm to use entropy you can set the `criterion` parameter when you create the `DecisionTreeClassifier`.\n",
    "\n",
    "Once you have a trained model replace `<model>` in the line of code below to plot the decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dec44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(<model>, class_names=iris_data['target_names'], feature_names=iris_data['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a397764",
   "metadata": {},
   "source": [
    "## 2. Evaluating Classifiers\n",
    "\n",
    "In the lectures we have been using the log-loss function to train our model but when it comes to providing metrics based on the final classifications there are three key methods you must be aware of. \n",
    "\n",
    "There are a number of benefits to using these metrics over log-loss, to start they are much easier to understand and explain. This is a huge benefit when describing results to non-technical stakeholders. Secondly they provide a good indication of which classes (when using multi-class and multi-label classification) our model is performing best on.\n",
    "\n",
    "The first and simplest measure is the accuracy of a model which is simply the number of correct predictions over the number of predictions. This gives a single metric covering all classes however this hides the complexity revealed by precision and recall:\n",
    "\n",
    "- Precision: The proportion of correctly identified positive cases.\n",
    "- Recall: The proportion of the total number of positives were identified.\n",
    "\n",
    "It is often common practice to average the precision and recall across all classes to provide a model-wide precision and recall. However, this again hides some complexity of the classifications.\n",
    "\n",
    "If you need any guidance throughout this task regarding Accuracy, Recall and Precision please refer to these articles:\n",
    "- [EvidentAI Article](https://www.evidentlyai.com/classification-metrics/multi-class-metrics)\n",
    "- [Builtin Article](https://builtin.com/data-science/precision-and-recall)\n",
    "\n",
    "\n",
    "### 2.1 TASK: Accuracy\n",
    "\n",
    "Your first task in this section is to implement the accuracy algorithm.\n",
    "\n",
    "Your method must take an array of predictions and an array of truth labels, and return an accuracy.\n",
    "\n",
    "Accuracy can be calculated as follows:\n",
    "\n",
    "$$ Accuracy(y, \\hat{y}) = \\frac{Correct Predictions}{Total Predictions}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f47346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d22026",
   "metadata": {},
   "source": [
    "### 2.2 TASK: Precision\n",
    "\n",
    "Next, implement a precision algorithm which will calculate a precision for each class and then provide an average precision for the model.\n",
    "\n",
    "Your method must take an array of predictions and an array of truth labels, and return an average precision.\n",
    "\n",
    "To calculate the precision of a given class you can perform the following calculation:\n",
    "\n",
    "$$ Precision_{0} = \\frac{TP_{0}}{TP_{0}+FP_{0}}$$\n",
    "\n",
    "Here, 0 is the class being calculated. $TP_{0}$ is the number of true positives (correctly identified) members of class 0 and $FP_{0}$ is the number of falsely identified members of the class.\n",
    "\n",
    "To calculate an average precision across all the classes iterate and take the average:\n",
    "\n",
    "$$ Average Precision = \\frac{1}{n}\\sum_{c=0}^{n}{Precision_{c}}$$\n",
    "\n",
    "Here, n is the number of possible classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117d565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffcca6fc",
   "metadata": {},
   "source": [
    "### 2.3 TASK: Recall\n",
    "\n",
    "Finally, implement a recall algorithm which will calculate a recall for each class and then provide an average recall for the model.\n",
    "\n",
    "Your method must take an array of predictions and an array of truth labels, and return an average precision.\n",
    "\n",
    "To calculate the recall of a given class you can perform the following calculation:\n",
    "\n",
    "$$ Recall_{0} = \\frac{TP_{0}}{TP_{0}+FN_{0}}$$\n",
    "\n",
    "Here, 0 is the class being calculated. $TP_{0}$ is the number of true positives (correctly identified) members of class 0 and $FN_{0}$ is the number of items in this class which have been falsely classified as a different class.\n",
    "\n",
    "To calculate an average recall across all the classes iterate and take the average:\n",
    "\n",
    "$$ Average Recall = \\frac{1}{n}\\sum_{c=0}^{n}{Recall_{c}}$$\n",
    "\n",
    "Here, n is the number of possible classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247a9f8e",
   "metadata": {},
   "source": [
    "## 3. Evaluating Classifiers\n",
    "\n",
    "Now it's time to evaluate the classifiers you generated earlier using the metrics you've implemented above. \n",
    "\n",
    "\n",
    "### 3.1 TASK: Predictions\n",
    "\n",
    "For both classifiers you created in section 1 generate predictions using the `test_x` dataset which contains unseen data. This means your classifier will hopefully perform worse than it would with `train_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30c5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dcbbfee",
   "metadata": {},
   "source": [
    "### 3.2 TASK: Evaluating\n",
    "\n",
    "Now, using the results from task 3.1 evaluate your classifiers using the metrics you have developed in section 2.\n",
    "\n",
    "Once you've calculated each of the metrics for both your classifiers compare and contrast the results. Which one would you prefer to deploy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f56db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "004fe983",
   "metadata": {},
   "source": [
    "## (Optional) Confusion Matrix\n",
    "\n",
    "Another way to visualise the performance of a classifier and in particular how your classifier has potentially mis-classified some of the dataset.\n",
    "\n",
    "Referring to the [Sklearn confusion matrix documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) use a confusion matrix to evaluate your two classifiers. Can you identify which of the classes your methods have performed well on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac3a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e68b8c8",
   "metadata": {},
   "source": [
    "## (Optional Extension) Decision Tree Pruning\n",
    "\n",
    "Pruning decision trees is a process which enables you to reduce the size of a decision tree by removing irrelevant and/or unimportant branches. For this final exercise I would like you to explore pruning techniques.\n",
    "- [StatQuest](https://www.youtube.com/watch?v=D0efHEJsfHo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaec005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
